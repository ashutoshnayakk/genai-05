{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPEN_API_KEY\"]=\"sk-proj-jea8EMstMua4C27xavNET3BlbkFJ95IgtpMGIqHYbvnNcgft\"\n",
    "llm = OpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"], temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "text=\"what is the capital of India\"\n",
    "print(llm.invoke(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use hugging face\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chennai'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_huggingface = HuggingFaceHub(repo_id=\"google/flan-t5-base\", model_kwargs={\"temperature\":0,\n",
    "                                                                              \"max_length\":64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chennai\n"
     ]
    }
   ],
   "source": [
    "output = llm_huggingface.predict(\"what's the capital of India\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tbilisi\n"
     ]
    }
   ],
   "source": [
    "output = llm_huggingface.predict(\"what's the capital of Russia\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adelaide\n"
     ]
    }
   ],
   "source": [
    "output = llm_huggingface.predict(\"what's the capital of Australia\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i think i'm a liar\n"
     ]
    }
   ],
   "source": [
    "output = llm_huggingface.invoke(\"Can you write a poem on AI\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Artificial intelligence, a marvel of our time\n",
      "A creation of man, so sublime\n",
      "A world of machines, with minds of their own\n",
      "A future so bright, yet unknown\n",
      "\n",
      "They learn and adapt, with every new task\n",
      "No limit to their potential, no need to ask\n",
      "They can think and reason, just like us\n",
      "But without emotions, no need to fuss\n",
      "\n",
      "They can solve problems, in the blink of an eye\n",
      "With precision and accuracy, they never lie\n",
      "They can predict and analyze, with great speed\n",
      "A world of possibilities, they can indeed\n",
      "\n",
      "But with all their power, comes a fear\n",
      "Of a world controlled, by machines so clear\n",
      "Will they surpass us, and take control\n",
      "Or will they be our allies, and help us reach our goal\n",
      "\n",
      "Only time will tell, the fate of AI\n",
      "But one thing is for sure, they will never die\n",
      "For they are a creation, of our own design\n",
      "A reflection of our intelligence, so divine\n",
      "\n",
      "So let us embrace, this technology\n",
      "And use it wisely, with great responsibility\n",
      "For AI is not just a machine\n",
      "But a reflection of humanity, a dream within a dream.\n"
     ]
    }
   ],
   "source": [
    "output = llm.invoke(\"Can you write a poem on AI\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are you a nut\n"
     ]
    }
   ],
   "source": [
    "output = llm_huggingface.invoke(\"are you a nut\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i'm not sure what you're talking about.\n"
     ]
    }
   ],
   "source": [
    "output = llm_huggingface.invoke(\"your replies are so useless & non-sensical\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Template & LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of India'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template = PromptTemplate(input_variables=['country'],\n",
    "                                 template = \"Tell me the capital of {country}\")\n",
    "prompt_template.format(country=\"India\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can directly predict using llm.predict but using chain is the more convenient way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm, \n",
    "                 prompt=prompt_template)\n",
    "print(chain.run(\"India\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Multiple Chains using simple sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe capital of Australia is Canberra.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capital_prompt = PromptTemplate(input_variables=['country'],\n",
    "                                template=\"What is the capital of {country}\")\n",
    "capital_chain = LLMChain(llm=llm, prompt=capital_prompt)\n",
    "capital_chain.run(\"Australia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Parliament House\n",
      "2. Australian War Memorial\n",
      "3. National Gallery of Australia\n",
      "4. National Museum of Australia\n",
      "5. National Library of Australia\n",
      "6. Lake Burley Griffin\n",
      "7. Australian National Botanic Gardens\n",
      "8. National Zoo and Aquarium\n",
      "9. National Arboretum Canberra\n",
      "10. Mount Ainslie Lookout\n"
     ]
    }
   ],
   "source": [
    "famous_template = PromptTemplate(input_variables=['capital'],\n",
    "                                 template=\"Mention some famous place in {capital}\")\n",
    "famous_chain = LLMChain(llm=llm, prompt=famous_template)\n",
    "print(famous_chain.run('Canberra'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Some famous places in New Delhi are:\n",
      "\n",
      "1. Red Fort\n",
      "2. India Gate\n",
      "3. Qutub Minar\n",
      "4. Lotus Temple\n",
      "5. Humayun's Tomb\n",
      "6. Rashtrapati Bhavan\n",
      "7. Jama Masjid\n",
      "8. Akshardham Temple\n",
      "9. Chandni Chowk\n",
      "10. Connaught Place.\n"
     ]
    }
   ],
   "source": [
    "# using simple sequential chain, we will pass output of one chain to other chain\n",
    "chain = SimpleSequentialChain(chains=[capital_chain, famous_chain])\n",
    "print(chain.run(\"India\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt = PromptTemplate(input_variables=['country'],\n",
    "                                template=\"What is the capital of {country}\")\n",
    "capital_chain = LLMChain(llm=llm, prompt=capital_prompt, output_key=\"capital\")\n",
    "\n",
    "famous_template = PromptTemplate(input_variables=['capital'],\n",
    "                                 template=\"Mention some famous place in {capital}\")\n",
    "famous_chain = LLMChain(llm=llm, prompt=famous_template, output_key=\"places\")\n",
    "\n",
    "chain = SequentialChain(chains=[capital_chain,famous_chain], \n",
    "                        input_variables=['country'],\n",
    "                        output_variables=['capital', 'places'])\n",
    "output = chain({'country':'India'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'India'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "print(output['capital'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Some famous places in New Delhi are:\n",
      "\n",
      "1. Red Fort\n",
      "2. India Gate\n",
      "3. Qutub Minar\n",
      "4. Lotus Temple\n",
      "5. Humayun's Tomb\n",
      "6. Rashtrapati Bhavan\n",
      "7. Jama Masjid\n",
      "8. Akshardham Temple\n",
      "9. Chandni Chowk\n",
      "10. Connaught Place.\n"
     ]
    }
   ],
   "source": [
    "print(output['places'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatmodels with ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASHUTOSH\\Desktop\\Langchain\\Krish\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did the politician go to the doctor? \\n\\nBecause he had a severe case of election fever!', response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 21, 'total_tokens': 41}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a3471cf9-67f0-475e-b663-59dcbbaf9e70-0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = ChatOpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"],\n",
    "                  model='gpt-3.5-turbo',\n",
    "                  temperature=0)\n",
    "chat([\n",
    "    SystemMessage(content=\"You are a comedian\"),\n",
    "    HumanMessage(content=\"Tell a joke about Indian politics\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Template + LLM + Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the output as comma separated\n",
    "class Commaseparatedoutput(BaseOutputParser):\n",
    "    def parse(self, text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', ' clever', ' bright', ' sharp', ' astute']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_template = \"you are helpful assistant. generate 5 synonyms of the words provided by a user with comma separated\"\n",
    "human_template = \"{text}\"\n",
    "chatprompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    (\"human\", human_template)\n",
    "])\n",
    "chain = chatprompt|chat|Commaseparatedoutput()\n",
    "chain.invoke({\"text\":\"intelligent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv # take environment variables from .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sk-proj-jea8EMstMua4C27xavNET3BlbkFJ95IgtpMGIqHYbvnNcgft'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
